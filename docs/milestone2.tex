\documentclass{article}
\usepackage[final]{nips_2017}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}
\usepackage{wrapfig}
\title{Family kinship Recognition Using Deep Learning}

\author{
  Bruce Jianye Liu\\
  Department of Computer Science\\
  Stanford University\\
  \texttt{bruceliu@stanford.edu} \\
}


\begin{document}
% \nipsfinalcopy is no longer used

\begin{center}
\includegraphics[width=3cm, height=0.7cm]{CS230}
\end{center}

\maketitle

\section{Problem Description}
Half of genetic information is passed down from parents to children. Therefore
people biologically related share delicate similiarities. This declicacy could
be easily caught by human eyes, looking at family photos. While computer vision
performance improving during the past decade, it becomes possible to use
meachine learning to capture the different. Computer vision based kinship
recognition could lead variety of usefull applications in reality such as
missing-children parents matching, family album organization, socal networking
apps, lost sibling/relatives searching, crime investigation. In this paper, we
propose a fine-tuned KinNet model to identify the relationship between two
faces -- parent-children, sibling-sibling, none-kinship, and same person. We
achieved 70 percent accuracy.

Solely relying on face pairs for kinship verification might be hard to achieve
higher accuracy since people without any family relation would look simliar to
each other. There are other metrics that we could consider to determine if the
kinship exists. Such information includes hands shape, nail types, foot toes,
ears, hairs. Due to time limitation and team size, we aren't able to collect
this data. Otherwise the prediction would improve a lot.

\section{Related Works}

Even thought many researcher have tried traditional approach to on image
recogintion tasks, Deep learning shows state-of-art achievement out-perform
other method by two order in computer image tasks. One of well-known image
recognition tasks is ImageNet[5] classification, which contains 14
million images labeled to roughly 22,000 catergories, and is widely used in
literacy as a large visual database for visual object recognition.

Starting from 2009, many neural network models are designed by researchers,
among them AlexNet[6] from University of Toronto in 2012, GoogLeNet
(Inception)[7] from Google in 2014, VGG[8] from Oxford Vision Geometry Group in
2015, and ResNet[9] form Microsoft Research showing significant impact on
academia. The error rate reached as low as 3.57\% surpassing human performance.

Beside Imagenet dataset, Labeled Faces in the Wild (LFW)[10] dataset and
Youtube Faces DB are widely used in face recognition tasks. Despite many other non-deep learning models have good performance, deep neural network models keep top records on this task, such as faceNet[2] designed by Schroff etc. achieved 99.63\% accuracy.

Similar to face verification problem, kinship recognition is another task that
attracts many researchers to put effect on.  Past kin recognition work mainly
focus on kinship verification, to decide whether two faces have kinship, family
classification, classifing a face to a family, and family member regcontion,
determining 2 faces siblings or parents. Over the past decades, many methods
has been proposed on this research, including hand-crafted feature, face
ecnodings, and metric learning[3].

\section{Dataset}

\begin{wrapfigure}{l}{0.25\textwidth}
\caption{108x124 face sample}
\includegraphics{img/P00241_face0}
\end{wrapfigure}

We are going to use Families In The Wild (FIW) Database[1]. FIW is the largest
and most comprehensive database available for kinship recognition. We use
version 0.1.2 at writing time, which include 13,188 faces from 1018 families.
Event though it has 11 kinship types, father-daughter (F-D), father-son (F-S),
mother-daughter (M-D), mother-son (M-S), brother-brother (B-B), sister-sister
(S-S), grandfather-granddaughter (GF-GD), grandfather-grandson (GF-GS),
grandmother-granddaughter (GM-GD), grandmother-grandson (GM-GS), to our study,
siblings and parent-child types are what we are going to use. Adding up 64669
F-D, 46143 F-S, 68935 M-D, 48940 M-S types, we get 22687 parent-child photos
while sibling types contains 55937 photos. All face images are 108*124*3 size.
The same face data is generated by selecting pictures with the same FaceID.
Non-related picture pairs are generated with pictures in the Family folder and
one of the faces in the family.

\begin{table}[h]
	\centering
	\begin{tabular}{ | c || r r | }
		\hline
		\multicolumn{3}{|c|}{face-pair image distribution} \\
		\hline
		pair types&face-pair number&percentage\\
		\hline
			parent-child & 228,687 &21.17\% \\
			siblings & 55,937 & 5.18\% \\
			same & 230,938 & 21.38\% \\
			unrelated & 564,496 & 52.27\% \\
		\hline
			& 1,080,058 & \\
		\hline
	\end{tabular}
	\caption{Training data distribution}
	\label{table:1}
\end{table}

Table 1 distrubtion may affect our model less confident to predict sibling
faces, while we may could do well on P-C, same faces, and non-related images.

There are another smaller family dataset KinFaceW-I and KinFaceW-II, which
includes 533 pairs of parent-child type images.


\section{Methods and Models}

Due to the original dataset uneven, training dataset are dividen into 6000
images as a test set, leaving the rest of the data as training. Both train set
and test set have equal number of image pair for each label, allowing the model
to learn evenly. Even we forsake some data volunterily, it is enought to train
the model.

In the first model, I took the InceptionResNetV2 model, removing the last full
connection layer and add global average last layer with 1536 dimension output,
following two dense layer with 1024, 128 units seperately. The finally layer is
a 4 node softmax output. For each face pair, I feed them into InceptionResNet
and get two 1536 vector which are concatenated into 3072 vector. This will feed
into dense layers to produce 4 output. Table 2 show detail architecture.

\begin{table}[h]
	\centering
	\begin{tabular}{ | l | c | c | c | c |}
		layer&size-in&size-out&param&FLPS\\
		\hline
			Input1 & 299x299x3 & & 0 & \\
			Input2 & 299x299x3 & & 0 & \\
			InceptionResNetV2 & 299x299x3 & 1x1536 & & \\
			InceptionResNetV2 & 299x299x3 & 1x1536 & & \\
			concat & 2x1536 & 1x3072 & & 0 \\
			fc1 & 1x3072 & 1x1024 & 3M & 3M \\
			fc2 & 1x1024 & 1x128 & 131K & 131K \\
			softmax & 1x1024 & 1x4 & 4100 & 4100 \\
		\hline
	\end{tabular}
	\caption{KinNet Layers}
	\label{table:2}
\end{table}

Each training time, I shuffled the dataset and take 5000 images to train.

The result is not ideal. I am not able to train it very well with my laptop
although I managed make the model work. I can't make through the first training
epoch. Loading the whole data into memory is still quite expensive on my local
machine, taking nearly 30 seconds. Going through 200 iterations costs about 20
minutes. After talking with TAs, he suggested to use aws gpu instance. It seems
this model I coded from scratch with numpy couldn't take advantage of GPU
processing power. The next milestone model could be any machine learning
framework such as Keras, Tensorflow or pytorch.

FaceNet[2] performs very well in face recognition tasks. I am going to tweak the
model little bits to create new model to classify image pairs.

\begin{figure}[h]
	\caption{Our modified model}
	\includegraphics[width=1\textwidth]{img/model_pic}
\end{figure}

One of the facenet implementation models is ResNet v1, which possibly have a
better performance than VGG-Face net. However it is very expensive to train as
it contains over 1 million parameters. Face kinship and face recogintion are
very similar problems. I am going to take pretrained model, fitting it my new
model, retain them. This could speed up the trainning process.

github repository: https://github.com/brucelau-github/cs230

\newpage
\section*{References}
\medskip
\small
[1] Robinson, Joseph P., et al. Families in the Wild (FIW): Large-Scale Kinship
Image Database and Benchmarks. {\it Proceedings of the 2016 ACM on Multimedia
Conference} - MM '16, 2016, doi:10.1145/2964284.2967219.

[2] Schroff, F., Kalenichenko, D., \& Philbin, J. (2015). FaceNet: A unified
embedding for face recognition and clustering. {\it 2015 IEEE Conference on
Computer Vision and Pattern Recognition (CVPR)}. doi: 10.1109/cvpr.2015.7298682

[3] Wang, S., Robinson, J. P., \& Fu, Y. (2017, May). Kinship verification on
families in the wild with marginalized denoising metric learning. {\it In 2017 12th
IEEE International Conference on Automatic Face \& Gesture Recognition (FG 2017)
(pp. 216-221). IEEE}.

[4] Szegedy, C., Ioffe, S., Vanhoucke, V., \& Alemi, A. A. (2017, February).
Inception-v4, inception-resnet and the impact of residual connections on
learning. In {\it Thirty-first AAAI conference on artificial intelligence}.

[5] Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K.,\& Fei-Fei, L. (2009).
ImageNet: A large-scale hierarchical image database. In {\it 2009 IEEE
conference on computer vision and pattern recognition} (pp. 248-255).

[6] Krizhevsky, Alex., Sutskever, I., \& Hinton, G. E. (2012). Imagenet
classification with deep convolutional neural networks. In {\it Advances in
neural information processing system} (pp. 1097-1105).

[7] Szegedy, c., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., ... \& Rabinovich, A. (2015). Going deeper with convolutions. In {\it Proceedings of the IEEE conference on computer vision and pattern recognition} (pp. 1-9)

[8] Simonyan, K., \& Zisserman, A. (2014). Very deep convolutional networks for large-scale image reognition. {\it arXiv preprint arXiv}: 1409. 1556.

[9] He, K., Zhang, X., Ren, S., \& Sun, J. (2016). Deep residual learning for image recognition. In {\it Proceedings of the IEEE conference on computer vision and pateern recognition} (pp. 770-778).

[10] Huang, G. B., Ramesh, M., Berg T., \& Learned-Miller, E. (2007) Labeled faces in the wild: a database for studying face recognition in unconstraned environments. In {\it Technical Report} 07-49, October 2017

\end{document}
